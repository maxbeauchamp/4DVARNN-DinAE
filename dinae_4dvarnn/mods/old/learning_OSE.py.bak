from dinae_4dvarnn import *
from sklearn import preprocessing
from tools import *
from graphics import *
from eval_Performance      import eval_AEPerformance2 as eval_AEPerformance
from eval_Performance      import eval_InterpPerformance2 as eval_InterpPerformance
from plot_Figs             import plot_Figs2 as plot_Figs
from save_Pickle           import save_Pickle2 as save_Pickle
from save_Models           import save_Models
from Model_4DVarNN_FP      import Model_4DVarNN_FP
from Model_4DVarNN_Grad    import Model_4DVarNN_Grad
from Model_4DVarNN_GradFP_OSE  import Model_4DVarNN_GradFP
from MultiSat_Loss         import MultiSat_Loss

def add_covariates_to_tensor(tensor1,tensor2,N_cov):
    new_tensor = np.zeros(tensor2.shape)
    index      = np.arange(0,tensor2.shape[1],N_cov+1)
    new_tensor[:,index,:,:] = tensor1.cpu().detach().numpy()
    index2      = np.delete(range(tensor2.shape[1]),index)
    new_tensor[:,index2,:,:] = (tensor2.cpu().detach().numpy())[:,index2,:,:]
    return torch.Tensor(new_tensor)

class MyDataParallel(torch.nn.DataParallel):
    """
    Allow nn.DataParallel to call model's attributes.
    """
    def __getattr__(self, name):
        try:
            return super().__getattr__(name)
        except AttributeError:
            return getattr(self.module, name)

def model_to_MultiGPU(model):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if torch.cuda.is_available():
        print('... Number of GPUs: %d'%torch.cuda.device_count())
        if torch.cuda.device_count() > 1:
            print("Let's use", torch.cuda.device_count(), "GPUs!")
            model      = MyDataParallel(model)
            model.model_AE   = MyDataParallel(model.model_AE)
            model.model_Grad = MyDataParallel(model.model_Grad)
    model.to(device)
    model.model_AE.to(device)
    model.model_Grad.to(device)
    return model

def learning_OSE(dict_global_Params,genFilename,meanTr,stdTr,\
                  x_inputs_train,mask_inputs_train,
                  x_targets_train,mask_targets_train,
                  sat_train,time_train,
                  x_train_OI,x_mod,lday_train,model_AE,DIMCAE):

    # import Global Parameters
    for key,val in dict_global_Params.items():
        exec("globals()['"+key+"']=val")

    # ***************** #
    # model compilation #
    # ***************** #

    ## model parameters
    NbProjection   = [2,2,5,5,10,12,15]
    NbGradIter     = [2,5,7,9,10,12,15]
    NbGradIter     = [0,0,0,0,0,0,0]
    lrUpdate       = [1e-3,1e-4,1e-5,1e-6]
    IterUpdate     = [0,3,10,15,20,25,30,35,40]

    #NbProjection   = [2,2,2,2,5,5,10,12,15]
    #NbGradIter     = [2,3,4,5,7,9,10,12,15]
    #lrUpdate       = [1e-3,1e-3,1e-3,1e-3,1e-3,1e-3,1e-4,1e-5,1e-6]
    #IterUpdate     = [0,1,2,3,10,15,20,25,30,35,40]
    
    val_split      = 0.1
    iterInit       = 0
    comptUpdate    = 0  
    ## modify/check data format
    x_inputs_train         = np.moveaxis(x_inputs_train, -1, 1)
    mask_inputs_train      = np.moveaxis(mask_inputs_train, -1, 1)
    x_targets_train        = np.moveaxis(x_targets_train, -1, 1)
    mask_targets_train     = np.moveaxis(mask_targets_train, -1, 1)
    sat_train              = np.moveaxis(sat_train, -1, 1)
    time_train             = np.moveaxis(time_train, -1, 1)
    x_mod                  = np.moveaxis(x_mod, -1, 1)

    # Replace NaN value with zeros
    x_inputs_train[np.isnan(x_inputs_train)]   = 0.
    x_targets_train[np.isnan(x_targets_train)] = 0.
    time_train[np.isnan(time_train)]           = 0.

    print("... Training datashape    : "+str(x_inputs_train.shape))
    pre = preprocessing.LabelEncoder()
    pre.fit(np.asarray(['','alg','h2g','j2g','j2n','j3','s3a']))
    list_Sat = torch.Tensor(pre.transform(sat_train.flatten()))
    ## define dataloaders with randomised batches (no random shuffling for validation/test data)
    training_dataset = torch.utils.data.TensorDataset(\
                            torch.Tensor(x_inputs_train),\
                            torch.Tensor(mask_inputs_train),\
                            torch.Tensor(x_targets_train),\
                            torch.Tensor(mask_targets_train),\
                            torch.Tensor(pre.transform(sat_train.flatten()).reshape(sat_train.shape)),\
                            torch.Tensor(time_train),
                            torch.Tensor(x_mod))
    dataset_sizes = {'train': len(training_dataset)} 
    ## instantiate model for GPU implementation
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(".... Device GPU: "+str(torch.cuda.is_available()))
    ## initialize or load the model (bug for number of FP iterations = 0) 
    shapeData       = x_inputs_train.shape[1:]  
    NBProjCurrent = NbProjection[0]
    NBGradCurrent = NbGradIter[0]
    print('..... DinAE learning (initialisation): NBProj = %d -- NGrad = %d'%(NBProjCurrent,NBGradCurrent))
    model = Model_4DVarNN_GradFP(\
              model_AE,shapeData,NBProjCurrent,NBGradCurrent,\
              flagGradModel,flagOptimMethod,N_cov=N_cov)    
    model =  model_to_MultiGPU(model)
    ## Model for loss function
    msloss = MultiSat_Loss(7)
    ## create an optimizer object (Adam with lr 1e-3)
    lrCurrent   = lrUpdate[0]
    lambda_LRAE = 0.5
    optimizer   = optim.Adam([{'params': model.model_Grad.parameters()},\
                              {'params': model.model_AE.encoder.parameters(),\
                               'lr': lambda_LRAE*lrCurrent},\
                              {'params': msloss.parameters(), 'lr': 0.1}\
                              ], lr=lrCurrent)

    ## adapt loss function parameters if learning only with observations
    model.model_Grad.compute_Grad.alphaObs = torch.nn.Parameter(torch.Tensor([np.sqrt(alpha4DVar[0])]).to(device))
    model.model_Grad.compute_Grad.alphaAE  = torch.nn.Parameter(torch.Tensor([np.sqrt(alpha4DVar[1])]).to(device))
    model.model_Grad.compute_Grad.alphaObs.requires_grad = False
    model.model_Grad.compute_Grad.alphaAE.requires_grad  = False
    alpha_Grad = alpha4DVar[0]
    alpha_AE   = alpha4DVar[1]
    
    ## model compilation 
    since = time.time()
    best_model_wts   = copy.deepcopy(model.state_dict())

    # ******************** #
    # Start Learning model #
    # ******************** #
        
    print("..... Start learning AE model %d FP/Grad %d"%(flagAEType,flagOptimMethod))
    best_loss      = 1e10
    for iter in range(iterInit,Niter):
        ## update number of FP projections, number of GB iterations, learning rate and the corresponding model
        if iter == IterUpdate[comptUpdate]:
            NBProjCurrent = NbProjection[comptUpdate]
            NBGradCurrent = NbGradIter[comptUpdate]
            lrCurrent     = lrUpdate[comptUpdate]
            print("..... Update/initialize number of projections/Graditer in GradCOnvAE model # %d/%d"%(NbProjection[comptUpdate],NbGradIter[comptUpdate]))
            # update GradFP architectures
            print('..... Update model architecture')
            model = Model_4DVarNN_GradFP(\
                      model_AE,shapeData,NBProjCurrent,NBGradCurrent,\
                      flagGradModel,flagOptimMethod,N_cov=N_cov)
            model =  model_to_MultiGPU(model)
            # update optimizer
            optimizer   = optim.Adam([{'params': model.model_Grad.parameters()},
                                    {'params': model.model_AE.encoder.parameters(), 'lr': lambda_LRAE*lrCurrent},\
                                    {'params': msloss.parameters(), 'lr': 0.1}\
                                    ], lr=lrCurrent)

            # copy model parameters from current model
            model.load_state_dict(best_model_wts)                            
            # update comptUpdate
            if comptUpdate < len(NbProjection)-1:
                comptUpdate += 1
        ## daloader for the training phase      
        train_set, val_set = torch.utils.data.random_split(training_dataset,
                                     [len(training_dataset)-int(len(training_dataset)*val_split),
                                     int(len(training_dataset)*val_split)])
        dataloaders = { 'train': torch.utils.data.DataLoader(train_set,\
                                 batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\
                        'val':   torch.utils.data.DataLoader(val_set,\
                                 batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)}

        ## run NbEpoc training epochs
        for epoch in range(NbEpoc):
            print('Epoc %d/%d'%(epoch,NbEpoc))
            # Each epoch has only a training phasein OSE setup
            for phase in ['train', 'val']:
                if phase == 'train':
                    model.train()  # Set model to training mode
                    print('..... Training step')
                else:
                    model.eval()   # Set model to evaluate mode
                    print('..... Test step')
                running_loss         = 0.0
                running_loss_All     = 0.
                running_loss_R       = 0.
                running_loss_I       = 0.
                running_loss_AE      = 0.
                num_loss     = 0
                # Iterate over data.
                compt = 0
                for inputs,mask_inputs,targets,mask_targets,sat,Time,NATL60 in dataloaders[phase]:
                    compt = compt+1
                    inputs         = inputs.to(device)
                    mask_inputs    = mask_inputs.to(device)
                    targets        = targets.to(device)
                    mask_targets   = mask_targets.to(device)
                    index          = np.arange(0,inputs.shape[1],N_cov+1)
                    index_OI       = np.arange(1,inputs.shape[1],N_cov+1)
                    OI             = inputs[:,index_OI,:,:]
                    sat            = sat.to(device)
                    Time           = Time.to(device)
                    NATL60         = NATL60.to(device)

                    # zero the parameter gradients
                    optimizer.zero_grad()
    
                    # forward
                    # need to evaluate grad/backward during the evaluation and training phase for model_AE
                    with torch.set_grad_enabled(True): 
                        inputs  = torch.autograd.Variable(inputs, requires_grad=True)
                        if model.OptimType == 1:
                            outputs,grad_new,normgrad = model(inputs,mask_inputs,None)
                        elif model.OptimType == 2:
                            outputs,hidden_new,cell_new,normgrad = model(inputs,mask_inputs,None,None)
                        else:
                            outputs,normgrad = model(inputs,mask_inputs)

                        ## Losses (to clean up...)
                        idT1 = int(np.floor(inputs.shape[1]/2))
                        idT2 = int(np.floor(targets.shape[1]/2))

                        # compute losses
                        loss_R      = torch.sum((outputs[:,idT2,:,:] - targets[:,idT2,:,:])**2 * mask_targets[:,idT2,:,:])
                        loss_R      = torch.mul(1.0 / torch.sum(mask_targets[:,idT2,:,:]),loss_R)
                        loss_I      = torch.sum((outputs[:,idT2,:,:] - targets[:,idT2,:,:])**2 * (1. - mask_targets[:,idT2,:,:]) )
                        loss_I      = torch.mul(1.0 / torch.sum(1.-mask_targets[:,idT2,:,:]),loss_I)
                        #loss_OI    = torch.sum((outputs[:,idT2,:,:] - OI[:,idT2,:,:])**2 * masks_targets[:,idT2,:,:] )
                        #loss_OI    = torch.mul(1.0 / torch.sum(masks_targets[:,idT2,:,:]),loss_OI)
                        loss_All    = torch.mean((outputs[:,idT2,:,:] - targets[:,idT2,:,:])**2 )
                        if N_cov>0:
                            outputs_wcov = add_covariates_to_tensor(outputs,inputs,N_cov).to(device) 
                            targets_wcov = add_covariates_to_tensor(targets,inputs,N_cov).to(device)
                            NATL60_wocov = NATL60[:,index,:,:]
                        else:
                            outputs_wcov = outputs
                            targets_wcov = targets
                            NATL60_wocov = NATL60
                        loss_NATL60 = torch.mean((model.model_AE(NATL60)[:,idT2,:,:] - NATL60_wocov[:,idT2,:,:])**2 )
                        index       = np.arange(0,inputs.shape[1],N_cov+1)
                        loss_Obs    = torch.sum( (outputs[:,idT2,:,:] - inputs[:,idT1,:,:])**2 * mask_inputs[:,idT1,:,:])
                        loss_Obs    = loss_Obs / torch.sum( mask_inputs[:,idT1,:,:] )

                        spatial_gradients_avg = einops.reduce(sobel(torch.unsqueeze(outputs[:,idT2,:,:],1)), 'b t lat lon -> 1', 'mean')
                        loss_Obs    = torch.sum( (outputs[:,idT2,:,:] - targets[:,idT2,:,:])**2 * mask_targets[:,idT2,:,:])
                        loss_Obs    = loss_Obs / torch.sum( mask_targets[:,idT2,:,:] )
                        loss_AE     = torch.mean((model.model_AE(outputs_wcov)[:,idT2,:,:] - outputs[:,idT2,:,:])**2 )
                        loss_AE_GT  = torch.mean((model.model_AE(targets_wcov)[:,idT2,:,:] - targets[:,idT2,:,:])**2 )

                        # Loss
                        loss        = alpha4DVar[0] * loss_Obs + alpha4DVar[1] * loss_AE + spatial_gradients_avg
                        #loss        = loss_R #+ loss_NATL60

                        if wregul==True:
                            '''print('loss_R={:4f}'.format(loss))
                            loss_G   = msloss(inputs[:,index[6],:,:],
                                            mask_targets[:,6,:,:],
                                            outputs[:,6,:,:],
                                            Time[:,6,:,:],
                                            sat[:,6,:,:])
                            print('loss_G={:4f}'.format(loss_G[0]))
                            loss    = torch.add(regul[0]*loss,\
                                                regul[1]*loss_G)'''

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
    
                    # statistics
                    running_loss             += loss.item() * inputs.size(0)
                    running_loss_I           += loss_I.item() * inputs.size(0)
                    running_loss_R           += loss_R.item() * inputs.size(0)
                    running_loss_All         += loss_All.item() * inputs.size(0)
                    running_loss_AE          += loss_AE_GT.item() * inputs.size(0)
                    num_loss                 += inputs.size(0)
    
                epoch_loss       = running_loss / num_loss
                epoch_loss_All   = running_loss_All / num_loss
                epoch_loss_AE    = running_loss_AE / num_loss
                epoch_loss_I     = running_loss_I / num_loss
                epoch_loss_R     = running_loss_R / num_loss
                        
                if not isinstance(stdTr, list) :
                    meanTr=[meanTr]
                    stdTr=[stdTr]

                epoch_nloss_All = epoch_loss_All / stdTr[0]**2
                epoch_nloss_I   = epoch_loss_I / stdTr[0]**2
                epoch_nloss_R   = epoch_loss_R / stdTr[0]**2
                epoch_nloss_AE  = loss_AE / stdTr[0]**2
            
                # deep copy the model
                if epoch_loss < best_loss:
                    best_loss = epoch_loss
                    best_model_wts = copy.deepcopy(model.state_dict())
                
                time_elapsed = time.time() - since
                print('Training complete in {:.0f}m {:.0f}s'.format(
                  time_elapsed // 60, time_elapsed % 60))
                print('Best val loss: {:4f}'.format(best_loss))


        # ********************************** #
        # Prediction on training & test data #
        # ********************************** #

        dataloaders = { 'train': torch.utils.data.DataLoader(training_dataset,\
                                 batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True) }

        ## load best model weights
        model.load_state_dict(best_model_wts)

        ## AE performance on training and validation datasets
        # outputs for training data
        x_train_pred = []
        for inputs,mask_inputs,targets,mask_targets,sat,Time,NATL60 in dataloaders['train']:
            inputs         = inputs.to(device)
            mask_inputs    = mask_inputs.to(device)
            targets        = targets.to(device)
            mask_targets   = mask_targets.to(device)
            with torch.set_grad_enabled(True): 
                outputs_ = model(inputs,mask_inputs)[0]
            if len(x_train_pred) == 0:
                x_train_pred  = torch.mul(1.0,outputs_).cpu().detach()
            else:
                x_train_pred  = np.concatenate((x_train_pred,\
                                   torch.mul(1.0,outputs_).cpu().detach().numpy()),axis=0)

        ## AE performance of the trained AE applied to gap-free data
        # ouputs for training data
        rec_AE_Tr = []
        for inputs,mask_inputs,targets,mask_targets,sat,Time,NATL60 in dataloaders['train']:
            inputs         = inputs.to(device)
            mask_inputs    = mask_inputs.to(device)
            targets        = targets.to(device)
            mask_targets   = mask_targets.to(device)
            if N_cov>0:
                targets_wcov = add_covariates_to_tensor(targets,\
                                inputs,N_cov).to(device)
            else:
                targets_wcov = targets
            with torch.set_grad_enabled(True): 
                outputs_ = model.model_AE(targets_wcov)
            print(outputs_.shape)
            if len(rec_AE_Tr) == 0:
                rec_AE_Tr  = torch.mul(1.0,outputs_).cpu().detach()
            else:
                rec_AE_Tr  = np.concatenate((rec_AE_Tr,\
                               torch.mul(1.0,outputs_).cpu().detach().numpy()),axis=0)
            print(rec_AE_Tr.shape)

        index = np.arange(0,x_inputs_train.shape[1],N_cov+1)
        mse_train,exp_var_train,\
        mse_train_interp,exp_var_train_interp=\
        eval_InterpPerformance(mask_targets_train,x_targets_train,x_train_pred)
        exp_var_AE_Tr = eval_AEPerformance(x_targets_train,rec_AE_Tr)
        
        if not isinstance(stdTr, list) :
            meanTr=[meanTr]
            stdTr=[stdTr]
        print(".......... iter %d"%(iter))
        print('.... Error for all data (Tr)        : %.2e %.2f%%'%(mse_train[1]*stdTr[0]**2,100.*exp_var_train[1]))
        print('....')
        print('.... Error for observed data (Tr)  : %.2e %.2f%%'%(mse_train[0]*stdTr[0]**2,100.*exp_var_train[0]))
        print('....')
        print('.... Error for masked data (Tr)  : %.2e %.2f%%'%(mse_train_interp*stdTr[0]**2,100.*exp_var_train_interp))

        # **************************** #
        # Plot figures and Save models #
        # **************************** #

        ## save models
        genSuffixModel=save_Models(dict_global_Params,genFilename,alpha4DVar,\
                                   NBProjCurrent,NBGradCurrent,model_AE,model,iter)

        ## resize according to dwscale
        if dwscale!=1:
            x_inputs_train = einops.reduce(inputs,  '(t t1) (c c1) (h h1) (w w1) -> t c h w',\
                                    t1=1, c1=1, h1=1/dwscale, w1=1/dwscale, reduction=np.nanmean)

        ## generate some plots
        plot_Figs(dict_global_Params,genFilename,genSuffixModel,\
                  x_targets_train,mask_targets_train,x_inputs_train,mask_inputs_train,x_train_pred,rec_AE_Tr,x_train_OI,meanTr[0],stdTr[0],\
                  lday_train,iter)

        ## save results in a pickle file
        save_Pickle(dict_global_Params,\
                    x_targets_train,x_inputs_train,x_train_pred,rec_AE_Tr,x_train_OI,meanTr[0],stdTr[0],\
                    iter)
